### Trimming and filtering RNA seq reads using BBduk (BBMap/38.95)

#!/bin/bash -l
#SBATCH --nodes=1
#SBATCH --mem-per-cpu=100G
#SBATCH --time=24:00:00
#SBATCH --output=bbduk.txt
#SBATCH --mail-user=wcoll010@ucr.edu
#SBATCH --mail-type=ALL
#SBATCH --job-name="bbduk"
#SBATCH -p highmem

cd $SLURM_SUBMIT_DIR

## Load BBMap module
module load BBMap

## G0 samples
bbduk.sh in1=G0_4_S206_L002_R2_001.fastq.gz \
         in2=G0_4_S206_L002_R1_001.fastq.gz \
         out1=bbduk/trimmed.G0_4_S206_L002_R2_001.fastq.gz \
         out2=bbduk/trimmed.G0_4_S206_L002_R1_001.fastq.gz \
         ref=adapters.fa ktrim=r mink=11 k=23 hdist=1 tbo tpe

bbduk.sh in1=G0_1_S203_L002_R2_001.fastq.gz \
         in2=G0_1_S203_L002_R1_001.fastq.gz \
         out1=bbduk/trimmed.G0_1_S203_L002_R2_001.fastq.gz \
         out2=bbduk/trimmed.G0_1_S203_L002_R1_001.fastq.gz \
         ref=adapters.fa ktrim=r mink=11 k=23 hdist=1 tbo tpe



# bbduk commands/settings
# ref=adapters.fa: Specifies a reference file containing adapter sequences to be removed from the reads.
# ktrim=r: Trims the right (3') end of reads matching any part of the adapter sequences.
# mink=11: Specifies the minimum k-mer length for k-mer matching. This is the minimum number of bases in a row that must match to trigger adapter trimming.
# k=23: Specifies the k-mer size to be used for k-mer matching. In this case, it's set to 23 bases.
# hdist=1: Specifies the maximum Hamming distance for k-mer matching. This allows for up to 1 mismatch when matching k-mers.
# tbo and tpe: These options indicate that adapter trimming is performed both when a k-mer from the read overlaps an adapter sequence (tbo), and when a k-mer from the adapter sequence overlaps the read (tpe).



### Checking read quality and statistics using fastQC (fastqc/0.11.9)

#!/bin/bash -l
#sbatch -N 1 -n 36 --mem 128gb -p intel --array=1-36 --out logs/bwa.%a.log --time 4:00:00
#SBATCH --mail-user=wcoll010@ucr.edu
#SBATCH --mail-type=ALL
#SBATCH --job-name="fastqc_reads"
#SBATCH --array=1-36
#SBATCH -p intel

CPU=2
if [ $SLURM_CPUS_ON_NODE ]; then
  CPU=$SLURM_CPUS_ON_NODE
fi

N=${SLURM_ARRAY_TASK_ID}
if [ -z $N ]; then
  N=$1
fi

if [ -z $N ]; then
  echo "cannot run without a number provided either cmdline or --array in sbatch"
  exit
fi

module load fastqc/0.11.9

# Define the folder containing the input files and the new output directory
INPUT_FOLDER="./trim_galore_results_new"
NEW_OUTPUT_FOLDER="./trim_galore_results_new/fastqc_results"

# Create the new output directory if it doesn't exist
mkdir -p $NEW_OUTPUT_FOLDER

# Get the list of all fastq.gz files in the input folder
trimmed_reads=($(ls $INPUT_FOLDER/*.fastq.gz))

# Calculate the total number of files
total_files=${#trimmed_reads[@]}

# Check if SLURM_ARRAY_TASK_ID is within the range of the number of files
if [ $SLURM_ARRAY_TASK_ID -le $total_files ]; then
    # Get the current file to process based on the array task ID
    current_file=${trimmed_reads[$((SLURM_ARRAY_TASK_ID-1))]}

    # Run fastqc on the current file
    fastqc -t $CPU $current_file -o $NEW_OUTPUT_FOLDER
else
    echo "Array task ID $SLURM_ARRAY_TASK_ID exceeds the number of files to process."
    exit 1
fi



### Aligning reads to the reference genome with STAR (star/2.7.10b)

#!/bin/bash -l
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=10
#SBATCH --mem-per-cpu=20G
#SBATCH --time=24:00:00     # 24h
#SBATCH --output=star_0111.txt
#SBATCH --mail-user=wcoll010@ucr.edu
#SBATCH --mail-type=ALL
# SBATCH --job-name="star_0111"
# SBATCH -p intel

# Load any necessary modules
module load star/2.7.10b

# Set the path to the genome directory
genome_dir="./genome_directory"

# Set the path to the output directory
output_dir="./results_2"
# List of sample names and corresponding fastq files
samples=(
  "G1_1 trimmed.G1_1_S207_L002_R2_001.fastq.gz trimmed.G1_1_S207_L002_R1_001.fastq.gz"
  "G1_2 trimmed.G1_2_S208_L002_R2_001.fastq.gz trimmed.G1_2_S208_L002_R1_001.fastq.gz"
  "G1_3 trimmed.G1_3_S209_L002_R2_001.fastq.gz trimmed.G1_3_S209_L002_R1_001.fastq.gz"
  "G1_4 trimmed.G1_4_S210_L002_R2_001.fastq.gz trimmed.G1_3_S210_L002_R1_001.fastq.gz"
)

# Loop through each sample and run STAR alignment
for sample in "${samples[@]}"; do
  sample_name=$(echo "$sample" | cut -d " " -f 1)
  read1=$(echo "$sample" | cut -d " " -f 2)
  read2=$(echo "$sample" | cut -d " " -f 3)

  # Create a unique output directory for each sample
  sample_output_dir="${output_dir}/${sample_name}"
  
# Run STAR alignment command
  STAR --genomeDir "$genome_dir" --runThreadN 10 \
  --readFilesCommand zcat --readFilesIn "$read1" "$read2" \
  --outFileNamePrefix "$sample_output_dir" --outSAMtype BAM SortedByCoordinate \
  --outSAMattributes Standard --outReadsUnmapped Fastx --outFilterIntronMotifs RemoveNoncanonical \
  --quantMode GeneCounts --twopassMode Basic --alignIntronMax 15000
done

